# Setting
SAMPLE = True

# Import libraries
from setting import *
from util import *

import os
import numpy as np
import pandas as pd

# Ignore warnings
import warnings
warnings.filterwarnings('ignore')

# Set display options
pd.options.display.max_rows = 100
pd.options.display.max_columns = 100
pd.options.display.width = 1000

# Set Global Random Seed -------------------------------------------------------
print_title('Set Global Random Seed')
np.random.seed(SEED)
print_info('Set global random seed to {}'.format(SEED))

# Load data --------------------------------------------------------------------
print_title('Load Data')
print_info('Start loading data')

if SAMPLE:
    origin_data = pd.read_csv(ORIGIN_DATA_PATH, nrows = 10000, dtype=ORIGIN_LOAD_TYPES, na_values=['UNKNOWN', 'Unknown'])
    # origin_data['MachineIdentifier'] = origin_data.index.astype('uint32')
else:
    origin_data = pd.read_csv(ORIGIN_DATA_PATH, dtype=ORIGIN_LOAD_TYPES, na_values=['UNKNOWN', 'Unknown'])
    # origin_data['MachineIdentifier'] = origin_data.index.astype('uint32')

print_info('Finish loading data')

# Get data summary of missing frequency and unique levels ----------------------
if SAMPLE and os.path.isfile(os.path.join(CHECK_DATA_DIRECTORY, 'data_summary.csv')):
    summary_df = pd.read_csv(os.path.join(CHECK_DATA_DIRECTORY, 'data_summary.csv'))
else:
    summary_df = origin_data.describe(include = 'all')
    summary_df = summary_df.transpose()
    summary_df.index.name = 'Column'
    summary_df['count'] = summary_df['count'].astype(int)
    missing_percentage_df = get_null_percentage(origin_data)
    missing_percentage_df = missing_percentage_df.set_index('Column')
    summary_df = pd.concat([summary_df, missing_percentage_df], axis = 1).reset_index()
summary_df = summary_df[summary_df['Column'] != TARGET]

# Features to be dropped -------------------------------------------------------
print_title('Drop Features')
print_info("Features with no relevance -> To be dropped:")
features_irrelevant= ['MachineIdentifier']
for col in features_irrelevant:
    print(col)

print_info("Features with more than half missing -> To be dropped:")
features_more_than_half_missing = list(summary_df[summary_df['Missing Frequency'] >= 0.5 ]['Column'])
for col in features_more_than_half_missing:
    print(col)

print_info("Features with 98% or more of the data contained in one category value -> To be dropped:")
summary_df['top_level_percentage'] = summary_df['freq'] / summary_df['count']
features_98_perc_in_one_category_value = list(summary_df[summary_df['top_level_percentage'] > 0.98]['Column'])
for col in features_98_perc_in_one_category_value:
    print(col)

features_to_be_dropped = list(set(features_irrelevant + features_more_than_half_missing + features_98_perc_in_one_category_value))
features_to_be_kept = [col for col in summary_df['Column'] if col not in features_to_be_dropped]
print_info("Leng of features with to be dropped: {}".format(len(features_to_be_dropped)))
for col in features_to_be_dropped:
    print(col)
print_info("Leng of features with to be kept: {}".format(len(features_to_be_kept)))
for col in features_to_be_kept:
    print(col)

summary_df = summary_df[summary_df['Column'].isin(features_to_be_kept)]

def select_features(df, features_to_be_dropped):
    print_info('Selecting features')
    df.drop(columns = features_to_be_dropped, inplace=True)
    print_info('No. of features dropped: {}'.format(len(features_to_be_dropped)))
    print_info("No. of features kept: {}".format(len(df.columns)))

select_features(origin_data, features_to_be_dropped)

# Fill missing values ----------------------------------------------------------
print_title('Identfy and Fill Missing Values')

features_missing_lt_1_perc = list(summary_df[(summary_df['Missing Frequency'].round(2) <= 0.01) & (summary_df['Missing Frequency'] != 0)]['Column'])
features_to_be_filled_by_mode = [col for col in features_missing_lt_1_perc if col in CATEGORICAL_FEATURES]
features_to_be_filled_by_median = [col for col in features_missing_lt_1_perc if col in NUMERICAL_FEATURES]
print_info("Features (categorical) with missing frequency <= 0.01 -> To be filled by mode:")
for col in features_to_be_filled_by_mode:
    print(col)
print_info("Features (numeric) with missing frequency <= 0.01 -> To be filled by median:")
for col in features_to_be_filled_by_median:
    print(col)

features_missing_mt_1_perc = list(summary_df[(summary_df['Missing Frequency'].round(2) > 0.01)]['Column'])
features_to_be_filled_by_unknown = [col for col in features_missing_mt_1_perc if col in CATEGORICAL_FEATURES]
print_info("Features (categorical) with missing frequency > 0.01 -> To be filled by unknown:")
for col in features_to_be_filled_by_unknown:
    print(col)
print_info("Features (numeric) with missing frequency > 0.01 -> To be ?:")
for col in [col for col in features_missing_mt_1_perc if col not in features_to_be_filled_by_unknown]:
    print(col)

# Census_InternalBatteryNumberOfCharges
print_info("Census_InternalBatteryNumberOfCharges (3.01% Missing & 25.38% are 4294967296 which represents inf in Python) - (filled with unknown & To be encoded)")
plot_continuous_distribution_as_box(origin_data[origin_data['Census_InternalBatteryNumberOfCharges'] != 4294967296], 'Census_InternalBatteryNumberOfCharges', save_directory = CHECK_DATA_IMAGE_DIRECTORY, show = False, title = 'Census_InternalBatteryNumberOfCharges (Clean)')
plot_continuous_distribution_as_box(origin_data[origin_data['Census_InternalBatteryNumberOfCharges'] != 4294967296], 'Census_InternalBatteryNumberOfCharges', category_column = TARGET, save_directory = CHECK_DATA_IMAGE_DIRECTORY, show = False, title = 'Census_InternalBatteryNumberOfCharges (Clean)')
plot_continuous_distribution_as_histogram(origin_data[origin_data['Census_InternalBatteryNumberOfCharges'] != 4294967296], 'Census_InternalBatteryNumberOfCharges', save_directory = CHECK_DATA_IMAGE_DIRECTORY, show = False, title = 'Census_InternalBatteryNumberOfCharges (Clean)')

def fill_missing_values(df, features_to_be_filled_by_mode = [], features_to_be_filled_by_median = [], features_to_be_filled_by_unknown = []):
    print_info('Filling missing values')
    for col in features_to_be_filled_by_mode:
        df[col] = df[col].fillna(df[col].mode()[0])
    for col in features_to_be_filled_by_median:
        df[col] = df[col].fillna(df[col].median())
    for col in features_to_be_filled_by_unknown:
        df[col] = df[col].cat.add_categories('unknown').fillna('unknown')
    df['Census_InternalBatteryNumberOfCharges'] = df['Census_InternalBatteryNumberOfCharges'].fillna('unknown')
    print_info('Count of missing values: {}'.format(df.isnull().sum().sum()))

fill_missing_values(origin_data, features_to_be_filled_by_mode, features_to_be_filled_by_median, features_to_be_filled_by_unknown)

# Invalid Values -----------------------------------------------------------
print_title('Identify and Handle Invalid Values')

# SmartScreen
print_info("SmartScreen (Different labels of same word with different case) - Lowercase values")
origin_data['SmartScreen']=origin_data['SmartScreen'].str.lower()
origin_data['SmartScreen'].replace({"promt":"prompt",
                                    "00000000":"0",
                                    "enabled":"on"},inplace=True)

plot_freq_and_rate(origin_data, 'SmartScreen', target = TARGET, save_directory = CHECK_DATA_IMAGE_DIRECTORY, title = 'SmartScreen (Clean)', show = False)

# Census_InternalPrimaryDisplayResolutionHorizontal
print_info("Census_InternalPrimaryDisplayResolutionHorizontal (invalid values as -1) - Convert invalid values -1 to median/mode")
origin_data['Census_InternalPrimaryDisplayResolutionHorizontal'] = origin_data['Census_InternalPrimaryDisplayResolutionHorizontal'].replace(-1, origin_data['Census_InternalPrimaryDisplayResolutionHorizontal'].median())
# get_percentage(origin_data, 'Census_InternalPrimaryDisplayResolutionHorizontal')

# Census_InternalPrimaryDisplayResolutionVertical
print_info("Census_InternalPrimaryDisplayResolutionVertical (invalid values as -1) - Convert invalid values -1 to median/mode")
origin_data['Census_InternalPrimaryDisplayResolutionVertical'] = origin_data['Census_InternalPrimaryDisplayResolutionVertical'].replace(-1, origin_data['Census_InternalPrimaryDisplayResolutionVertical'].median())
# get_percentage(origin_data, 'Census_InternalPrimaryDisplayResolutionVertical')

def handle_invalid_values(df):
    print_info('Handling invalid values')
    df['SmartScreen']=df['SmartScreen'].str.lower()
    df['SmartScreen'].replace({"promt":"prompt",
                               "00000000":"0",
                               "enabled":"on"},inplace=True)
    df['Census_InternalPrimaryDisplayResolutionHorizontal'] = df['Census_InternalPrimaryDisplayResolutionHorizontal'].replace(-1, df['Census_InternalPrimaryDisplayResolutionHorizontal'].median())
    df['Census_InternalPrimaryDisplayResolutionVertical'] = df['Census_InternalPrimaryDisplayResolutionVertical'].replace(-1, df['Census_InternalPrimaryDisplayResolutionVertical'].median())

handle_invalid_values(origin_data)

# Identify and Handle Outliers For Numeric Attributes --------------------------
# Binning @TODO
print_title('Identify and Handle Outliers')

# AVProductsInstalled
print_info("AVProductsInstalled - Do Nothing")

# AVProductsEnabled
print_info("AVProductsEnabled - Do Nothing")

# Census_ProcessorCoreCount
print_info("Census_ProcessorCoreCount - Do Nothing")

# Census_PrimaryDiskTotalCapacity
print_info("Census_PrimaryDiskTotalCapacity - Remove rows with extreme outlier values (Smooth Out Later)") # 8160436813824.0 6523912192000.0
# outliers_df = origin_data[origin_data['Census_PrimaryDiskTotalCapacity'] > (10**12)]
# print("The two extremely large outliers: {}".format(list(outliers_df['Census_PrimaryDiskTotalCapacity'].unique())))
# print("Number of outliers removed: {}".format(outliers_df.shape[0]))
# origin_data = origin_data[origin_data['Census_PrimaryDiskTotalCapacity'] < (10**12)]

# Census_SystemVolumeTotalCapacity
print_info("Census_SystemVolumeTotalCapacity - Do Nothing (Smooth Out Later)")

# Census_TotalPhysicalRAM
print_info("Census_TotalPhysicalRAM - Do Nothing (Smooth Out Later)")

# Census_InternalPrimaryDiagonalDisplaySizeInInches @TODO
print_info("Census_InternalPrimaryDiagonalDisplaySizeInInches - Do Nothing (Smooth Out Later)")

# Census_InternalPrimaryDisplayResolutionHorizontal @TODO
print_info("Census_InternalPrimaryDisplayResolutionHorizontal - Do Nothing (Smooth Out Later)")

# Census_InternalPrimaryDisplayResolutionVertical @TODO
print_info("Census_InternalPrimaryDisplayResolutionVertical - Do Nothing (Smooth Out Later)")

# Census_InternalBatteryNumberOfCharges
print_info("Census_InternalBatteryNumberOfCharges - Do Nothing")


def remove_outliers(df):
    outliers_df = df[df['Census_PrimaryDiskTotalCapacity'] > (10**12)]
    print("The two extremely large outliers: {}".format(list(outliers_df['Census_PrimaryDiskTotalCapacity'].unique())))
    print("Number of outliers removed: {}".format(outliers_df.shape[0]))
    df = df[df['Census_PrimaryDiskTotalCapacity'] < (10**12)]

remove_outliers(origin_data)


# Normalize Numeric Features ------------------------------------------------------------------
print_title('Normalize Numeric Features')
features_need_NM = [col for col in NUMERICAL_FEATURES if col in features_to_be_kept]
features_need_NM.remove('Census_PrimaryDiskTotalCapacity')
print_info("No. of numeric features to be normalized: {}".format(len(features_need_NM)))
for col in features_need_NM:
    print(col)

# Encode Categorical Features ---------------------------------------------------------------------
print_title('Encode Categorical Features')
features_binary = [col for col in list(summary_df[summary_df['unique'] == 2]['Column']) if col not in features_missing_mt_1_perc]
features_need_EN = list(set([col for col in list(summary_df[summary_df['unique'] > 2]['Column'])] + features_to_be_filled_by_unknown))
features_need_EN.append('Census_PrimaryDiskTotalCapacity')
features_need_BE = {}
features_need_TE = {}
features_need_FE = []


print_info("No. of categorical features with binary levels (0/1 by default) -> Do Nothing: {}".format(features_binary))
for col in features_binary:
    print(col)

print_info("No. of categorical features with more than 2 levels -> To be encoded: {}".format(len(features_need_EN)))
for col in features_need_EN:
    print(col)

# @TODO
# Time feature ----------------------------------------------------------------
features_versions = [col for col in features_to_be_kept if col.lower().endswith('version') or col.lower().endswith('ver')]
print_info("Features (version/ver) indicating time -> To be engineered:")
for col in features_versions:
    print(col)

# @TODO
# Related features -------------------------------------------------------------
features_related = [['EngineVersion','AvSigVersion'],
                    ['OsVer', 'Census_OSVersion'],
                    ['CountryIdentifier', 'CityIdentifier', 'GeoNameIdentifier', 'LocaleEnglishNameIdentifier'],
                    ['OsVer', 'OsBuild', 'OsSuite', 'OsPlatformSubRelease', 'OsBuildLab', 'Census_OSVersion', 'Census_OSArchitecture', 'Census_OSBranch', 'Census_OSBuildNumber', 'Census_OSBuildRevision'],
                    ['Census_OEMNameIdentifier', 'Census_OEMModelIdentifier'],  # Some CountryIdentifier have duplicated CityIdentifier]
                    ['Census_ProcessorManufacturerIdentifier', 'Census_ProcessorModelIdentifier'], # Census_ProcessorModelIdentifier for a Census_ProcessorManufacturerIdentifier
                    ['Census_OSEdition', 'Census_OSSkuName']]

print_info("Features related -> To be explored & engineered:")
for col in features_related:
    print(col)

# @TODO
# Data Encoding ----------------------------------------------------------------
print_title('Feature Encoding')

column = 'RtpStateBitfield'
labels = ['7', '0']
df = origin_data
target = TARGET
target_mean = 0.5
labels_count = 3

def encode_BE(df, column, labels):
    print_info('Binary Encoding {}: {}'.format(column, labels))
    for label in labels:
        df['{}_BE_{}'.format(column, label)] = (df[column] == label).astype(int)
    return ['{}_BE_{}'.format(column, label) for label in labels]

def encode_TE_train(df, column, labels, target, target_mean):
    print_info('Target Encoding {}: {}'.format(column, labels))
    column_df = df[[column, target]]
    column_df['target_sum'] = column_df[column].map(column_df.groupby([column])[target].sum())
    column_df['target_sum_leave_one_out'] = column_df['target_sum'] - column_df[target]
    df['{}_TE'.format(column)] = column_df.apply(lambda row: row['target_sum_leave_one_out'] / column_df.shape[0] if row[column] in labels else mean, 1).fillna(target_mean)

    encoding = {key:value for key, value in dict(column_df.groupby([column])[target].mean()).items() if key in labels}
    return encoding

def encode_TE_test(df, column, encoding, target_mean):
    print_info('Target Encoding {}: {}'.format(column, labels))
    df['{}_TE'.format(column)] = df[column].map(encoding).fillna(target_mean)

def encode_FE_train(df, column):
    encoding = df[column].value_counts()
    encoding = encoding / encoding.max()
    encoding = dict(encoding)
    df['{}_FE'.format(column)] = df[column].map(encoding)
    print_info('Frequency Encoding {}: corr(target, {} = {})'.format(column, column, df[['{}_FE'.format(column), target]].corr().iloc[0][1]))

    return encoding

def encode_FE_test(df, column, encoding):
    print_info('Frequency Encoding {}'.format(column))
    df['{}_FE'.format(column)] = df[column].map(encoding)

# Census_InternalBatteryNumberOfCharges
print_info("Census_InternalBatteryNumberOfCharges (3.01% Missing & 25.38% are 4294967296 which represents inf in Python) - (To be encoded)")
encode_BE()

# RtpStateBitfield
print_info("RtpStateBitfield (7 unique levels & Low frequency levels) - Feature to be encoded")

# AVProductStatesIdentifier
print_info("AVProductStatesIdentifier (29870 unique levels & Low frequency levels) - Feature to be encoded")

# CountryIdentifier
print_info("CountryIdentifier (222 unique levels) - Feature to be encoded")

# CityIdentifier
print_info("CityIdentifier (107366 unique levels) - Feature to be encoded")
# df = origin_data.groupby(['CountryIdentifier', 'CityIdentifier'])['MachineIdentifier'].count().reset_index()
# df[df['CityIdentifier'].isin(df[df.duplicated(subset = ['CityIdentifier'])]['CityIdentifier'])].sort_values(['CityIdentifier']).shape

# OrganizationIdentifier
print_info("OrganizationIdentifier (49 unique levels) - Feature to be encoded")

# GeoNameIdentifier
print_info("GeoNameIdentifier (292 unique levels) - Feature to be encoded")
# df = origin_data.groupby(['CountryIdentifier', 'GeoNameIdentifier'])['MachineIdentifier'].count().reset_index()
# df[df['GeoNameIdentifier'].isin(df[df.duplicated(subset = ['GeoNameIdentifier'])]['GeoNameIdentifier'])].sort_values(['GeoNameIdentifier'])

# LocaleEnglishNameIdentifier
print_info("LocaleEnglishNameIdentifier (276 unique levels) - Feature to be encoded")

# Platform
print_info("Platform (4 unique levels) - Feature to be encoded")

# Processor
print_info("Processor (4 unique levels) - Feature to be encoded")

# OsBuild
print_info("OsBuild (76 unique levels) - Feature to be encoded")

# OsSuite
print_info("OsSuite (14 unique levels) - Feature to be encoded")

# OsPlatformSubRelease
print_info("OsPlatformSubRelease (9 unique levels) - Feature to be encoded")

# SkuEdition
print_info("SkuEdition (8 unique levels & Low frequency levels) - Feature to be encoded")

# IeVerIdentifier
print_info("IeVerIdentifier (303 unique levels) - Feature to be encoded")

# SmartScreen
print_info("SmartScreen (21 unique levels - Feature to be encoded")

# Census_MDC2FormFactor
print_info("Census_MDC2FormFactor (13 unique levels) - Feature to be encoded")

# Census_OEMNameIdentifier
print_info("Census_OEMNameIdentifier (3832 unique levels) - Feature to be encoded")

# Census_OEMModelIdentifier
print_info("Census_OEMModelIdentifier (175365 unique levels) - Feature to be encoded")
# len(origin_data['Census_OEMModelIdentifier'].unique())
# df = origin_data.groupby(['Census_OEMNameIdentifier', 'Census_OEMModelIdentifier'])['MachineIdentifier'].count().reset_index()
# df.shape
# df[df['Census_OEMModelIdentifier'].isin(df[df.duplicated(subset = ['Census_OEMModelIdentifier'])]['Census_OEMModelIdentifier'])].sort_values(['Census_OEMModelIdentifier'])
# origin_data[(~pd.isna(origin_data['Census_OEMNameIdentifier'])) & (pd.isna(origin_data['Census_OEMModelIdentifier']))].shape
# origin_data[(pd.isna(origin_data['Census_OEMNameIdentifier'])) & (~pd.isna(origin_data['Census_OEMModelIdentifier']))].shape
# origin_data[(pd.isna(origin_data['Census_OEMNameIdentifier'])) & (pd.isna(origin_data['Census_OEMModelIdentifier']))].shape

# Census_ProcessorManufacturerIdentifier
print_info("Census_ProcessorManufacturerIdentifier (7 unique levels & Low frequency levels) - Feature to be encoded")

# Census_ProcessorModelIdentifier
print_info("Census_ProcessorModelIdentifier (3428 unique levels) - Feature to be encoded")
# len(origin_data['Census_ProcessorModelIdentifier'].unique())
# df = origin_data.groupby(['Census_ProcessorManufacturerIdentifier', 'Census_ProcessorModelIdentifier'])['MachineIdentifier'].count().reset_index()
# df.shape
# df[df['Census_ProcessorModelIdentifier'].isin(df[df.duplicated(subset = ['Census_ProcessorModelIdentifier'])]['Census_ProcessorModelIdentifier'])].sort_values(['Census_ProcessorModelIdentifier'])
# origin_data[(~pd.isna(origin_data['Census_ProcessorManufacturerIdentifier'])) & (pd.isna(origin_data['Census_ProcessorModelIdentifier']))].shape
# origin_data[(pd.isna(origin_data['Census_ProcessorManufacturerIdentifier'])) & (~pd.isna(origin_data['Census_ProcessorModelIdentifier']))].shape
# origin_data[(pd.isna(origin_data['Census_ProcessorManufacturerIdentifier'])) & (pd.isna(origin_data['Census_ProcessorModelIdentifier']))].shape

# Census_PrimaryDiskTypeName
print_info("Census_PrimaryDiskTypeName (5 unique levels) - To be encoded")
# origin_data['Census_PrimaryDiskTypeName'] = origin_data['Census_PrimaryDiskTypeName'].fillna('UNKNOWN')
# get_percentage(origin_data, 'Census_PrimaryDiskTypeName')

# Census_ChassisTypeName
print_info("Census_ChassisTypeName () - Feature to be encoded")

# Census_PowerPlatformRoleName
print_info("Census_PowerPlatformRoleName () - Feature to be encoded")

# Census_OSArchitecture
print_info("Census_OSArchitecture (3 unique levels) - Feature to be encoded")

# Census_OSBranch
print_info("Census_OSBranch (32 unique levels) - Feature to be encoded")

# Census_OSBuildNumber
print_info("Census_OSBuildNumber (165 unique levels) - Feature to be encoded")

# Census_OSBuildRevision
print_info("Census_OSBuildRevision (285 unique levels) - Feature to be encoded")

# Census_OSEdition
print_info("Census_OSEdition (33 unique levels) - Feature to be encoded")

# Census_OSSkuName
print_info("Census_OSSkuName (30 unique levels) - Feature to be encoded")

# Census_OSInstallTypeName
print_info("Census_OSInstallTypeName (9 unique levels) - Feature to be encoded")

# Census_OSInstallLanguageIdentifier
print_info("Census_OSInstallLanguageIdentifier (39 unique levels) - Feature to be encoded")

# Census_OSUILocaleIdentifier
print_info("Census_OSUILocaleIdentifier (147 unique levels) - Feature to be encoded")

# Census_OSWUAutoUpdateOptionsName
print_info("Census_OSWUAutoUpdateOptionsName (6 unique levels) - Feature to be encoded")

# Census_GenuineStateName
print_info("Census_GenuineStateName (5 unique levels) - Feature to be encoded")

# Census_ActivationChannel
print_info("Census_ActivationChannel (6 unique levels) - Feature to be encoded")

# Census_FlightRing
print_info("Census_ActivationChannel (10 unique levels) - Feature to be encoded")

# Census_FirmwareManufacturerIdentifier
print_info("Census_FirmwareManufacturerIdentifier () - Feature to be encoded")

# Census_FirmwareVersionIdentifier
print_info("Census_FirmwareVersionIdentifier () - Feature to be encoded")

# Wdft_IsGamer
print_info("Wdft_IsGamer (3 unique levels) - To be encoded")

# Wdft_RegionIdentifier
print_info("Wdft_RegionIdentifier () - To be encoded")


# Feature Engineering ----------------------------------------------------------
print_title('Feature Engineering')

print_sub_title('Time Features')
# EngineVersion
print_info("EngineVersion (Indicating Time) - Feature to be engineered")

# AppVersion
print_info("AppVersion (Indicating Time) - Feature to be engineered")

# AvSigVersion
print_info("AvSigVersion (Indicating Time) - Feature to be engineered")

# OsVer
print_info("OsVer (58 unique levels & Indicating Time) - Feature to be engineered")

# OsBuildLab
print_info("OsBuildLab (663 unique levels & Indicating Time) - engineered - https://www.kaggle.com/nroman/hacking-osbuildlab-feature-updated")

# Census_OSVersion
print_info("Census_OSVersion (Indicating Time) - Feature to be engineered")


print_sub_title('Related Features')
# origin_data.info()
origin_data.isnull().sum()

# CLEANED_ORIGIN_DATA_PATH = os.path.join(DATA_PATH, 'origin_clean.csv')
# origin_data.to_csv(CLEANED_ORIGIN_DATA_PATH, index = False)


# for filename in os.listdir(os.path.join(CHECK_DATA_DIRECTORY, 'category_counts')):
#     if filename.endswith("csv"):
#         df = pd.read_csv(os.path.join(CHECK_DATA_DIRECTORY, 'category_counts', filename))
#         if -1 in list(df['Label']):
#             print(filename)
