"""#### Import Libraries"""
from setting import *

import random
import os
from datetime import date, timedelta, datetime
import pickle

import numpy as np
import pandas as pd

import matplotlib
matplotlib.use('agg')

import matplotlib.pyplot as plt
import seaborn as sns

# Set figure aesthetics
# plt.style.use('fivethirtyeight')
sns.set_style('white')
PLOT_HEIGHT = 6
PLOT_WIDTH = PLOT_HEIGHT * 1.618
plt.rcParams["figure.figsize"] = [PLOT_WIDTH,PLOT_HEIGHT]

# Ignore warnings
import warnings
warnings.filterwarnings('ignore')

""" Utility Functions """
def current_time():
    return str(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

def print_title(title):
    print()
    print(' {} '.format(title).center(100, '='))

def print_sub_title(title):
    print()
    print(' {} '.format(title).center(100, '-'))

def print_info(info):
    print("{:<6} {}: {}".format('[INFO]', current_time(), info))

def check_dir(directory):
    if not os.path.exists(directory):
        check_dir(os.path.dirname(directory))
        os.mkdir(directory)
        print_info('Make directory: {}'.format(directory))

for dir in DIRECTORY_TO_CHECK:
    check_dir(dir)

def convert_filename(filename):
    for unacceptable in [' ', ':', '.', '(', ')']:
        filename = filename.replace(unacceptable, '_')
    return filename

def save_obj(obj, fpath):
    with open(fpath, 'wb') as f:
        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)

def load_obj(fpath):
    with open(fpath, 'rb') as f:
        return pickle.load(f)

"""Check Data"""
def get_null_percentage(data):
    df = data.isnull().sum().reset_index().rename(columns = {0: 'Missing Count', 'index': 'Column'})
    df['Missing Frequency'] = df['Missing Count'] / data.shape[0]
    df['Missing Frequency %'] = (df['Missing Frequency'] * 100).round(2)
    return df

def display_category_counts(data, categorical_features, save_directory = None, is_print = False):
    if save_directory:
        check_dir(os.path.join(save_directory))
    for categorical_feature in categorical_features:
        print('-' * 30)
        print(categorical_feature)
        category_counts_df = data[categorical_feature].value_counts(dropna=False).reset_index()
        category_counts_df.columns = ['Label', 'Count']
        category_counts_df['Frequency'] = category_counts_df['Count'] / data.shape[0]
        category_counts_df['Frequency %'] = (category_counts_df['Frequency'] * 100).round(2)

        if is_print:
            print(category_counts_df)
        if save_directory:
            category_counts_df.to_csv(os.path.join(save_directory, '{}.csv'.format(categorical_feature)), index = False)

def get_percentage(data, column):
    count_df = data[column].value_counts(dropna=False).reset_index().rename(columns = {column: 'Count', 'index': column})
    count_df['%'] = count_df['Count'] / data.shape[0]
    return count_df

def find_outlier_limits(data, feature):
    IQR = data[feature].quantile(0.75) - data[feature].quantile(0.25)

    upper_limit = data[feature].quantile(0.75) + (IQR * 1.5)
    upper_limit_extreme = data[feature].quantile(0.75) + (IQR * 3)
    upper_limit, upper_limit_extreme

    lower_limit = data[feature].quantile(0.25) - (IQR * 1.5)
    lower_limit_extreme = data[feature].quantile(0.25) - (IQR * 3)
    lower_limit, lower_limit_extreme

    total = np.float(data.shape[0])
    print('Outliers higher than UPPER LIMIT {}: {:%}'.format(upper_limit, data[data[feature]>upper_limit].shape[0]/total))
    print('Outliers higher than UPPER LIMIT EXTREME {}: {:%}'.format(upper_limit_extreme, data[data[feature]>upper_limit_extreme].shape[0]/total))
    print('Outliers higher than UPPER LIMIT {}: {:%}'.format(lower_limit, data[data[feature]>upper_limit].shape[0]/total))
    print('Outliers higher than UPPER LIMIT EXTREME {}: {:%}'.format(lower_limit_extreme, data[origin_data[feature]>upper_limit_extreme].shape[0]/total))

    return {'upper_limit': upper_limit,
            'upper_limit_extreme':upper_limit_extreme,
            'lower_limit': lower_limit,
            'lower_limit_extreme': lower_limit_extreme}

"""Manipulate Data"""
def convert_minority_to_others(data, column_name, minority_counts = 0):
    minorities = list(data.groupby([column_name]).size().reset_index().rename(columns = {0: 'Count'}).sort_values('Count').head(minority_counts)[column_name])
    data[column_name + '_min_to_other'] = data[column_name].apply(lambda value: 'other' if value in minorities else value)
    print(data[column_name + '_min_to_other'].value_counts())

"""Save & Load Models"""
def save_label_encoder(label_encoder, model_name):
    check_dir(MODEL_PATH)
    np.save(os.path.join(MODEL_PATH, model_name + '.npy'), label_encoder.classes_)

from sklearn.preprocessing import LabelEncoder
def load_label_encoder(model_name):
    label_encoder = LabelEncoder()
    label_encoder.classes_ = np.load(os.path.join(MODEL_PATH, model_name + '.npy'))
    return label_encoder

import pickle
def save_model(model, model_name):
    check_dir(MODEL_PATH)
    pickle.dump(model, open(os.path.join(MODEL_PATH, model_name + '.sav'), 'wb'))

def load_model(model_name):
    return pickle.load(open(os.path.join(MODEL_PATH, model_name + '.sav'), 'rb'))

"""Plotting"""
def convert_column_name_to_title(column_name):
    return column_name.replace('_', ' ').title()

def plot_pie(data, column_name, title = None, save = False, show = True):
    temp = data[column_name].value_counts()
    temp = pd.DataFrame({'labels': temp.index,
                       'values': temp.values
                      })
    values = temp['values']
    labels = temp['labels']

    fig = plt.figure(figsize=(12, 12), facecolor='w')
    bbox_props = dict(boxstyle="round", fc="w", ec="0.5", alpha=0.4)
    patches = plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=90, pctdistance = 0.95,
        textprops={'fontsize': 16, 'bbox': bbox_props})

    plt.axis('equal')

    if title is None:
        title = 'Distribution of ' + column_name

    plt.title(title, loc = 'center', y=1.1, fontsize = 25)
    plt.tight_layout()

    if save:
        check_dir(IMAGE_PIE_DIRECTORY)
        saved_path = os.path.join(IMAGE_PIE_DIRECTORY, convert_filename(title))
        fig.savefig(saved_path, dpi=200, bbox_inches="tight")
        print('Saved to {}'.format(saved_path))
    if show:
        plt.show()
    plt.close()

def plot_catogory_distribution(data, category_column, title = None, percentage = False, rot = 0, save_directory = None, show = True, cut = 12):
    fig = plt.figure(facecolor='w', figsize=(PLOT_WIDTH, PLOT_HEIGHT))

    if percentage == False:
        data[category_column].value_counts(dropna=False)[:cut].plot(kind='bar', color = 'c', rot = 0)
    else:
        (data[category_column].value_counts(dropna=False) / data.shape[0]*100)[:cut].plot(kind='bar', color = 'c', rot = rot)

    if percentage == False:
        plt.ylabel('No. of users')
    else:
        plt.ylabel('% of users')

    if title is None:
        title = 'Distribution of ' + category_column
        if percentage:
            title = 'Percentage ' + title

    plt.title(title, loc = 'center', y=1.1, fontsize = 25)
    plt.tight_layout()

    if save_directory:
        check_dir(save_directory)
        check_dir(os.path.join(save_directory, 'bar'))
        saved_path = os.path.join(os.path.join(save_directory, 'bar'), convert_filename(title))
        fig.savefig(saved_path, dpi=200, bbox_inches="tight")
        print('Saved to {}'.format(saved_path))
    if show:
        plt.show()

    plt.close()

def plot_continuous_distribution_as_histogram(data, continuous_column, title = None, bins = None, save_directory = None, show = True):
    fig = plt.figure(facecolor='w', figsize=(PLOT_WIDTH, PLOT_HEIGHT))

    sns.distplot(data[continuous_column].dropna(), bins = bins, kde = False)

    if title is None:
        title = 'Distribution of ' + continuous_column
    plt.title(title, loc = 'center', y=1.1, fontsize = 25)
    plt.tight_layout()

    if save_directory:
        check_dir(save_directory)
        check_dir(os.path.join(save_directory, 'histogram'))
        saved_path = os.path.join(save_directory, 'histogram', convert_filename(title))
        fig.savefig(saved_path, dpi=200, bbox_inches="tight")
        print('Saved to {}'.format(saved_path))
    if show:
        plt.show()

    plt.close()

def plot_continuous_distribution_as_box(data, continuous_column, category_column = None, title = None, save_directory = None, show = True):
    fig = plt.figure(facecolor='w', figsize=(PLOT_WIDTH, PLOT_HEIGHT))

    sns.boxplot(y = continuous_column , x = category_column, data = data, color = 'c')
    if title is None:
        title = 'Distribution of ' + continuous_column
        if category_column is not None:
            title = title + ' By ' + category_column
    plt.title(title, loc = 'center', y=1.1, fontsize = 25)
    plt.tight_layout()

    if save_directory:
        check_dir(save_directory)
        check_dir(os.path.join(save_directory, 'boxplot'))
        saved_path = os.path.join(save_directory, 'boxplot', convert_filename(title))
        fig.savefig(saved_path, dpi=200, bbox_inches="tight")
        print('Saved to {}'.format(saved_path))
    if show:
        plt.show()

    plt.close()

def plot_freq_and_rate(data, category_column, target, cut = 12, title = None, save_directory = None, show = True):

    data = data[[category_column, target]]
    data[category_column] = data[category_column].astype('str')

    freq_df = (data[category_column].value_counts(dropna=False) / data.shape[0]*100).reset_index()
    freq_df.columns = [category_column, 'Frequency %']
    rate_df = data.groupby([category_column])[target].mean().reset_index()
    rate_df.columns = [category_column, target + ' Rate']
    df = freq_df.merge(rate_df)
    df = df.sort_values('Frequency %', ascending = False)[:cut]
    df[category_column] = df[category_column].replace('nan', 'NA')

    # plot density and detection rate
    fig = plt.figure(1, facecolor='w', figsize=(PLOT_HEIGHT * 3, PLOT_HEIGHT))
    ax1 = fig.add_subplot(1,1,1)
    ax1.bar(list(df[category_column]),list(df['Frequency %']),color='c', label = 'Frequency %')
    ax2 = ax1.twinx()
    ax2.plot(list(df[category_column]),list(df[target + ' Rate']), color = 'black', marker = 'o', linestyle='dashed', lw = 2, label = target+' Rate')
    ax2.spines['left'].set_color('c')
    ax2.set_ylabel(target+ ' Rate', color='k')
    ax2.yaxis.label.set_color('k')
    ax2.yaxis.label.set_fontsize(20)
    for label in ax2.yaxis.get_majorticklabels():
        label.set_fontsize(16)
    ax1.spines['left'].set_color('c')
    ax1.set_ylabel('Frequency %', color='c')
    ax1.yaxis.label.set_color('c')
    ax1.yaxis.label.set_fontsize(20)
    ax1.tick_params(axis='y', colors='c', labelsize=16)
    ax1.tick_params(axis='x', colors='k', labelsize=16)
    # y = [data[target].mean()] * df.shape[0]
    # plt.plot(df[category_column], y, 'r:', linewidth = 2)
    # fig.legend(fontsize = 16)
    fig.legend(fontsize = 16)

    if title is None:
        title = category_column
    plt.title(title, loc = 'center', y=1.1, fontsize = 25)
    plt.tight_layout()

    if save_directory:
        check_dir(save_directory)
        check_dir(os.path.join(save_directory, 'freq_rate'))
        saved_path = os.path.join(save_directory, 'freq_rate', convert_filename(title))
        fig.savefig(saved_path, dpi=200, bbox_inches="tight", facecolor = 'white')
        print('Saved to {}'.format(saved_path))
    if show:
        plt.show()

    plt.close()

def plot_heatmap(data, title = None, save_directory = False, show = True):
    fig = plt.figure(facecolor='w', figsize=(PLOT_WIDTH * 1.1, PLOT_WIDTH))
    sns.heatmap(data, cmap="YlGnBu")

    if title is None:
        title = 'Heatmap for {} ..'.format(data.columns[0])

    plt.title(title, loc = 'center', y=1.1, fontsize = 25)
    plt.xlabel('Month')
    plt.ylabel('Day of the Week')
    plt.tight_layout()

    if save_directory:
        check_dir(save_directory)
        check_dir(os.path.join(save_directory, 'heatmap'))
        saved_path = os.path.join(save_directory, 'heatmap', convert_filename(title))
        fig.savefig(saved_path, dpi=200, bbox_inches="tight")
        print('Saved to {}'.format(saved_path))
    if show:
        plt.show()

    plt.close()

from sklearn.metrics import roc_curve, auc, roc_auc_score
def plot_roc_curve(y_true, y_prob, title = None, save_directory = None, show = True):
    fig = plt.figure(facecolor='w', figsize=(PLOT_HEIGHT, PLOT_HEIGHT * 1.1))

    fpr, tpr, threshold = roc_curve(y_true, y_prob)
    roc_auc = roc_auc_score(y_true, y_prob)

    plt.plot(fpr, tpr, 'c', label = 'AUC = %0.3f' % roc_auc)
    plt.legend(loc = 'lower right', fontsize=16)
    plt.plot([0, 1], [0, 1],'k--')
    plt.xlim([0, 1])
    plt.ylim([0, 1])
    plt.ylabel('True Positive Rate', fontsize=16)
    plt.xlabel('False Positive Rate', fontsize=16)
    plt.tick_params(labelsize=16)

    if title is None:
        title = 'ROC Curve'
    plt.title(title, loc = 'center', y=1.1, fontsize = 20)
    plt.tight_layout()

    if save_directory:
        check_dir(save_directory)
        check_dir(os.path.join(save_directory, 'roc'))
        saved_path = os.path.join(save_directory, 'roc', convert_filename(title))
        fig.savefig(saved_path, dpi=200, bbox_inches="tight")
        print('Saved to {}'.format(saved_path))
    if show:
        plt.show()

    plt.close()

def plot_pca_ratio_cumsum(cumsum, title = None, save_directory = None, show = True):
    fig = plt.figure(facecolor='w', figsize=(PLOT_WIDTH, PLOT_HEIGHT))
    x = [i for i in range(1, len(cumsum)+1)]
    plt.plot(x, cumsum)
    plt.ylabel('No. of Components', fontsize=16)
    plt.xlabel('Explained Variance Ratio', fontsize=16)
    plt.tick_params(labelsize=16)

    if title is None:
        title = 'PCA Explained Variance Ratio by No. of Components'
    plt.title(title, loc = 'center', y=1.1, fontsize = 20)
    plt.tight_layout()

    if save_directory:
        check_dir(save_directory)
        saved_path = os.path.join(save_directory, convert_filename(title))
        fig.savefig(saved_path, dpi=200, bbox_inches="tight")
        print('Saved to {}'.format(saved_path))
    if show:
        plt.show()

    plt.close()

# Data Encoding ----------------------------------------------------------------
def encode_BE(df, column, labels):
    print_info('Binary Encoding {}: {}'.format(column, labels))
    for label in labels:
        df['{}_BE_{}'.format(column, label)] = (df[column] == label).astype(int)
    return ['{}_BE_{}'.format(column, label) for label in labels]

def encode_TE_train(df, column, labels, target, target_mean):
    print_info('Target Encoding {}: {}'.format(column, labels))
    column_df = df[[column, target]]
    column_df['target_sum'] = column_df[column].map(column_df.groupby([column])[target].sum())
    column_df['target_sum_leave_one_out'] = column_df['target_sum'] - column_df[target]
    df['{}_TE'.format(column)] = column_df.apply(lambda row: row['target_sum_leave_one_out'] / column_df.shape[0] if row[column] in labels else mean, 1).fillna(target_mean)

    encoding = {key:value for key, value in dict(column_df.groupby([column])[target].mean()).items() if key in labels}
    return encoding

def encode_TE_test(df, column, encoding, target_mean):
    print_info('Target Encoding {}: {}'.format(column, labels))
    df['{}_TE'.format(column)] = df[column].map(encoding).fillna(target_mean)

def encode_FE_train(df, column):
    encoding = df[column].value_counts()
    encoding = encoding / encoding.max()
    encoding = dict(encoding)
    df['{}_FE'.format(column)] = df[column].map(encoding)
    print_info('Frequency Encoding {}: corr(target, {} = {})'.format(column, column, df[['{}_FE'.format(column), target]].corr().iloc[0][1]))

    return encoding

def encode_FE_test(df, column, encoding):
    print_info('Frequency Encoding {}'.format(column))
    df['{}_FE'.format(column)] = df[column].map(encoding)
