# Setting
SAMPLE = True

# Import libraries
from setting import *
from util import *

import gc
import os
import random
import numpy as np
import pandas as pd
import tensorflow as tf
from keras import backend as K

os.environ['PYTHONHASHSEED']=str(SEED)
tf.set_random_seed(SEED)
np.random.seed(SEED)
random.seed(SEED)
session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)
sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)
K.set_session(sess)

from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import roc_curve, auc, roc_auc_score
from sklearn.decomposition import PCA
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from keras.models import Sequential
from keras.layers import Dense, BatchNormalization
from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, Callback
import lightgbm as lgb

# Ignore warnings
import warnings
warnings.filterwarnings('ignore')

# Set display options
pd.options.display.max_rows = 100
pd.options.display.max_columns = 100
pd.options.display.width = 1000


# Set Global Random Seed -------------------------------------------------------
print_title('Set Global Random Seed')
np.random.seed(SEED)
print_info('Set global random seed to {}'.format(SEED))

# Load data --------------------------------------------------------------------
print_title('Load Data')
print_info('Start loading data')

if not os.path.isfile(ORIGIN_DATA_PATH):
    print_info("File '{}' does not exist.".format(ORIGIN_DATA_PATH))
    print_info("Please download it according to the instructions in README.md")
    quit()

if SAMPLE:
    origin_data = pd.read_csv(ORIGIN_DATA_PATH, nrows = 30000, dtype=ORIGIN_LOAD_TYPES, na_values=['UNKNOWN', 'Unknown'])
    # origin_data['MachineIdentifier'] = origin_data.index.astype('uint32')
else:
    origin_data = pd.read_csv(ORIGIN_DATA_PATH, dtype=ORIGIN_LOAD_TYPES, na_values=['UNKNOWN', 'Unknown'])
    # origin_data['MachineIdentifier'] = origin_data.index.astype('uint32')

print_info('Finish loading data')

# Get data summary of missing frequency and unique levels ----------------------
print_title('Get Data Summary')
if SAMPLE and os.path.isfile(os.path.join(CHECK_DATA_DIRECTORY, 'data_summary.csv')):
    print_info('Read from existing data_summary.csv')
    summary_df = pd.read_csv(os.path.join(CHECK_DATA_DIRECTORY, 'data_summary.csv'))
else:
    print_info('Creating data summary')
    summary_df = origin_data.describe(include = 'all')
    summary_df = summary_df.transpose()
    summary_df.index.name = 'Column'
    summary_df['count'] = summary_df['count'].astype(int)
    missing_percentage_df = get_null_percentage(origin_data)
    missing_percentage_df = missing_percentage_df.set_index('Column')
    summary_df = pd.concat([summary_df, missing_percentage_df], axis = 1).reset_index()
summary_df = summary_df[summary_df['Column'] != TARGET]

# Drop Features ----------------------------------------------------------------
print_title('Drop Features')

print_info("Features with no relevance -> To be dropped:")
features_irrelevant= ['MachineIdentifier']
for col in features_irrelevant:
    print(col)

print_info("Features with more than half missing -> To be dropped:")
features_more_than_half_missing = list(summary_df[summary_df['Missing Frequency'] >= 0.5 ]['Column'])
for col in features_more_than_half_missing:
    print(col)

print_info("Features with 98% or more of the data contained in one category value -> To be dropped:")
summary_df['top_level_percentage'] = summary_df['freq'] / summary_df['count']
features_98_perc_in_one_category_value = list(summary_df[summary_df['top_level_percentage'] > 0.98]['Column'])
for col in features_98_perc_in_one_category_value:
    print(col)

features_to_be_dropped = list(set(features_irrelevant + features_more_than_half_missing + features_98_perc_in_one_category_value))
features_to_be_kept = [col for col in summary_df['Column'] if col not in features_to_be_dropped]
print_info("Leng of features with to be dropped: {}".format(len(features_to_be_dropped)))
for col in features_to_be_dropped:
    print(col)
print_info("Leng of features with to be kept: {}".format(len(features_to_be_kept)))
for col in features_to_be_kept:
    print(col)

def select_features(df, features_to_be_dropped):
    print_info('Selecting features')
    df.drop(columns = features_to_be_dropped, inplace=True)
    print_info('No. of features dropped: {}'.format(len(features_to_be_dropped)))
    print_info("No. of features kept: {}".format(len(df.columns)))
select_features(origin_data, features_to_be_dropped)
summary_df = summary_df[summary_df['Column'].isin(features_to_be_kept)]

# Fill missing values ----------------------------------------------------------
print_title('Identfy and Fill Missing Values')

features_missing_lt_1_perc = list(summary_df[(summary_df['Missing Frequency'].round(2) <= 0.01) & (summary_df['Missing Frequency'] != 0)]['Column'])
features_to_be_filled_by_mode = [col for col in features_missing_lt_1_perc if col in CATEGORICAL_FEATURES]
features_to_be_filled_by_median = [col for col in features_missing_lt_1_perc if col in NUMERICAL_FEATURES]
print_info("Features (categorical) with missing frequency <= 0.01 -> To be filled by mode:")
for col in features_to_be_filled_by_mode:
    print(col)
print_info("Features (numeric) with missing frequency <= 0.01 -> To be filled by median:")
for col in features_to_be_filled_by_median:
    print(col)

features_missing_mt_1_perc = list(summary_df[(summary_df['Missing Frequency'].round(2) > 0.01)]['Column'])
features_to_be_filled_by_unknown = [col for col in features_missing_mt_1_perc if col in CATEGORICAL_FEATURES]
print_info("Features (categorical) with missing frequency > 0.01 -> To be filled by unknown:")
for col in features_to_be_filled_by_unknown:
    print(col)
print_info("Features (numeric) with missing frequency > 0.01 -> To be ?:")
for col in [col for col in features_missing_mt_1_perc if col not in features_to_be_filled_by_unknown]:
    print(col)

def fill_missing_values(df, features_to_be_filled_by_mode = [], features_to_be_filled_by_median = [], features_to_be_filled_by_unknown = []):
    print_info('Filling missing values')
    for col in features_to_be_filled_by_mode:
        df[col] = df[col].fillna(df[col].mode()[0])
    for col in features_to_be_filled_by_median:
        df[col] = df[col].fillna(df[col].median())
    for col in features_to_be_filled_by_unknown:
        df[col] = df[col].cat.add_categories('unknown').fillna('unknown')
    df['Census_InternalBatteryNumberOfCharges'] = df['Census_InternalBatteryNumberOfCharges'].fillna('unknown').astype('str')
    print_info('Count of missing values: {}'.format(df.isnull().sum().sum()))

fill_missing_values(origin_data, features_to_be_filled_by_mode, features_to_be_filled_by_median, features_to_be_filled_by_unknown)

# Handle Invalid Values --------------------------------------------------------
print_title('Identify and Handle Invalid Values')
def handle_invalid_values(df):
    print_info('Handling invalid values')
    df['SmartScreen']=df['SmartScreen'].str.lower()
    df['SmartScreen'].replace({"promt":"prompt",
                               "00000000":"0",
                               "enabled":"on"},inplace=True)
    df['Census_InternalPrimaryDisplayResolutionHorizontal'] = df['Census_InternalPrimaryDisplayResolutionHorizontal'].replace(-1, df['Census_InternalPrimaryDisplayResolutionHorizontal'].median())
    df['Census_InternalPrimaryDisplayResolutionVertical'] = df['Census_InternalPrimaryDisplayResolutionVertical'].replace(-1, df['Census_InternalPrimaryDisplayResolutionVertical'].median())

handle_invalid_values(origin_data)

# Identify and Handle Outliers For Numeric Attributes --------------------------
print_title('Identify and Handle Outliers')
def remove_outliers(df):
    outliers_df = df[df['Census_PrimaryDiskTotalCapacity'] > (10**12)]
    print("The two extremely large outliers: {}".format(list(outliers_df['Census_PrimaryDiskTotalCapacity'].unique())))
    print("Number of outliers removed: {}".format(outliers_df.shape[0]))
    df = df[df['Census_PrimaryDiskTotalCapacity'] < (10**12)]

remove_outliers(origin_data)

"""@TODO"""
# https://www.kaggle.com/cdeotte/time-series-eda-malware-0-64/notebook
# Encode ---------------------------------------------------------------------
print_title('Encode Categorical Features')
features_binary = [col for col in list(summary_df[summary_df['unique'] == 2]['Column']) if col not in features_missing_mt_1_perc]
features_need_EN = list(set([col for col in list(summary_df[summary_df['unique'] > 2]['Column'])] + features_to_be_filled_by_unknown))
features_need_EN.append('Census_InternalBatteryNumberOfCharges')
# features_need_BE = {}
# features_need_TE = {}
# features_need_FE = []

print_info("No. of categorical features with binary levels (0/1 by default) -> Do Nothing: {}".format(len(features_binary)))
for col in features_binary:
    print(col)
    origin_data[col] = origin_data[col].astype('int8')

print_info("No. of categorical features with more than 2 levels -> To be encoded: {}".format(len(features_need_EN)))
for col in features_need_EN:
    print(col)

le = LabelEncoder()
for col in features_need_EN:
    origin_data[col] = le.fit_transform(origin_data[col])

"""@TODO Split by Time"""
# Split Train and Test ---------------------------------------------------------
print_title('Split Train and Test')
print_info('Start splitting data')
origin_y = origin_data[TARGET]
origin_x = origin_data.drop(columns = TARGET)
train_x, test_x, train_y, test_y = train_test_split(origin_x, origin_y, test_size=0.3, stratify = origin_y, random_state = SEED)
print_info('Trainser shape: {} | Testset shape: {}'.format(train_x.shape, test_x.shape))
print_info('Trainset Distribution: ')
print(train_y.value_counts() / train_y.shape[0])
print_info('Testset Distribution: ')
print(test_y.value_counts() / test_y.shape[0])

# Normalizing ------------------------------------------------------------------
print_title('Normalize Numeric Features')
# features_need_NM = [col for col in NUMERICAL_FEATURES if col in features_to_be_kept]
# features_need_NM.remove('Census_InternalBatteryNumberOfCharges')
# print_info("No. of numeric features to be normalized: {}".format(len(features_need_NM)))
# for col in features_need_NM:
#     # train_x[col] = scaler.fit_transform(train_x[[col]])
#     print(col)
scaler = MinMaxScaler()
train_x[train_x.columns] = scaler.fit_transform(train_x)
test_x[train_x.columns] = scaler.transform(test_x)
test_x.describe()

# PCA --------------------------------------------------------------------------
print_info('Finding n_components that could explain at least 90% variances')
pca = PCA(n_components=train_x.shape[-1])
pca.fit(train_x)
ratio_cumsum = pca.explained_variance_ratio_.cumsum()
ratio_df = pd.DataFrame(data = { 'No. of Components': range(1, len(pca.explained_variance_ratio_)+1),'Explained Variance Ratio': pca.explained_variance_ratio_, 'Cum Explained Variance Ratio': ratio_cumsum})
ratio_df.to_csv(os.path.join(RESULTS_DIRECTORY, 'PCA_Explained_Variance_Ratio.csv'), index = False)
plot_pca_ratio_cumsum(ratio_cumsum, save_directory=RESULTS_IMAGE_DIRECTORY, show = False)

N_COMPONENTS = sum(ratio_cumsum<0.95)+1
pca = PCA(n_components=N_COMPONENTS)
pca.fit(train_x)
ratio_cumsum = pca.explained_variance_ratio_.cumsum()
print_info('Explained variance by {} n_components: {:.3f}'.format(N_COMPONENTS, ratio_cumsum[-1]))

# Build Model ------------------------------------------------------------------
def pca_transform(train_x, test_x):
    pca = PCA(n_components=N_COMPONENTS)
    train_x = pca.fit_transform(train_x)
    test_x = pca.transform(test_x)
    print_info('PCA transformed train_x shape: {}'.format(train_x.shape))
    return train_x, test_x

def grid_search(estimator_name, estimator, train_x, train_y, pca):
    print_info('Start Grid Searching {}'.format(estimator_name))
    gridsearcher = GridSearchCV(estimator, param_grid = estimators_params_grid[estimator_name], **gridsearch_param)
    gridsearcher.fit(train_x, train_y)
    cv_results_df = pd.DataFrame(gridsearcher.cv_results_)
    cv_results_df.to_csv(os.path.join(RESULTS_FT_DIRECTORY, 'cv_results-{}{}.csv'.format(estimator_name, '+PCA' if pca else '')), index = False)

    save_obj(gridsearcher.best_params_, os.path.join(RESULTS_FT_DIRECTORY, 'FT-Best_Params-{}{}.pkl'.format(estimator_name, '+PCA' if pca else '')))
    save_obj(gridsearcher.best_estimator_.get_params(), os.path.join(RESULTS_FT_DIRECTORY, 'Params-{}{}.pkl'.format(estimator_name, '+PCA' if pca else '')))

    print_info('Grid Search best ROC Score: {}'.format(gridsearcher.best_score_))
    print('Best Params: \n{}'.format(gridsearcher.best_params_))

    return gridsearcher.best_estimator_, gridsearcher.best_estimator_.get_params()

def make_prediction(model, train_x, test_x, estimator_name, pca, fine_tune):
    print_info('Start Making Prediction with Best Estimator {}'.format(estimator_name))

    if estimator_name == 'NeuralNetwork':
        train_predict = model.predict(train_x)
        test_predict = model.predict(test_x)
    elif estimator_name == 'LGBMClassifier':
        train_predict = model.predict_proba(train_x)[:, -1]
        test_predict = model.predict_proba(test_x)[:, -1]
        model.best_iteration_
    else:
        train_predict = model.predict_proba(train_x)[:, -1]
        test_predict = model.predict_proba(test_x)[:, -1]

    return train_predict, test_predict

def save_score(estimator_name, pca, fine_tune, train_roc_score, test_roc_score):
    scores_fpath = os.path.join(RESULTS_DIRECTORY, 'scores.csv')
    try:
        scores_df = pd.read_csv(scores_fpath)
    except:
        scores_df = pd.DataFrame(columns = ['Model', 'PCA', 'Fine Tune', 'Train ROC Score', 'Test ROC Score'])

    scores_df.loc[scores_df.shape[0]] = [estimator_name, pca, fine_tune, train_roc_score, test_roc_score]
    scores_df.to_csv(scores_fpath, index = False)

def process_prediction(model, train_prob, train_y, test_prob, test_y, estimator_name, pca, fine_tune):

    plot_roc_curve(train_y, train_prob, save_directory = RESULTS_IMAGE_DIRECTORY, show = False, title = '{} ROC Curve - {}{}{}'.format('Train', estimator_name, '+PCA' if pca else '', '+FT' if fine_tune else ''))
    plot_roc_curve(test_y, test_prob, save_directory = RESULTS_IMAGE_DIRECTORY, show = False, title = '{} ROC Curve - {}{}{}'.format('Test', estimator_name, '+PCA' if pca else '', '+FT' if fine_tune else ''))

    train_roc_score = roc_auc_score(train_y, train_prob)
    test_roc_score = roc_auc_score(test_y, test_prob)

    # Save settings and score
    save_score(estimator_name, pca, fine_tune, train_roc_score, test_roc_score)

    print_info('ROC Score for {}: {:.3f} (Train)'.format(estimator_name, train_roc_score))
    print_info('ROC Score for {}: {:.3f} (Test)'.format(estimator_name, test_roc_score))

    # Save prediction results
    np.save(os.path.join(RESULTS_PREDICTION_DIRECTORY, 'train-{}{}{}'.format(estimator_name, '+PCA' if pca else '', '+FT' if fine_tune else '')), train_prob)
    np.save(os.path.join(RESULTS_PREDICTION_DIRECTORY, 'test-{}{}{}'.format(estimator_name, '+PCA' if pca else '', '+FT' if fine_tune else '')), test_prob)

def process_feature_importances(model, importances, estimator_name, pca, fine_tune):
    """@TODO"""
    if not importances:
        if estimator_name == 'LogisticRegression':
            importances = model.coef_
        else:
            importances = model.feature_importances_
    importances_df = pd.DataFrame(data = {'Column': list(train_x.columns), 'Importance': importances.reshape(-1,)})
    importances_df.sort_values('Importance', ascending = False, inplace = True)
    importances_df.to_csv(os.path.join(RESULTS_IMPORTANCE_DIRECTORY, '{}{}{}.csv'.format(estimator_name, '+PCA' if pca else '', '+FT' if fine_tune else '')), index = False)


from tensorflow import numpy_function
from tensorflow import double
def auroc(y_true, y_pred):
    return numpy_function(roc_auc_score, (y_true, y_pred), double)


def build_nn(train_x):
    model = Sequential()
    model.add(Dense(512, input_dim=train_x.shape[1], kernel_initializer='normal', activation='relu'))
    # model.add(BatchNormalization())
    # model.add(Dropout(0.2))
    #
    # model.add(Dense(256, activation='relu'))
    # model.add(BatchNormalization())
    # model.add(Dropout(0.2))
    #
    # model.add(Dense(128, activation='relu'))
    # model.add(BatchNormalization())
    # model.add(Dropout(0.2))
    #
    # model.add(Dense(64, activation='relu'))
    # model.add(BatchNormalization())
    # model.add(Dropout(0.2))
    #
    # model.add(Dense(32, activation='relu'))
    # model.add(BatchNormalization())
    # model.add(Dropout(0.2))
    #
    # model.add(Dense(16, activation='relu'))
    # model.add(BatchNormalization())
    # model.add(Dropout(0.2))
    #
    # model.add(Dense(8, activation='relu'))
    # model.add(BatchNormalization())
    # model.add(Dropout(0.2))

    model.add(Dense(1, activation='sigmoid'))

    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auroc])

    return model

def plot_nn_history(history):
    import matplotlib.pyplot as plt

    auroc = history.history['auroc']
    val_auroc = history.history['val_auroc']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    epochs = range(1,len(auroc)+1)

    fig = plt.figure(facecolor='w', figsize=(PLOT_WIDTH, PLOT_HEIGHT))
    plt.plot(epochs, auroc,'r',label='Training AUC')
    plt.plot(epochs, val_auroc,'b',label='Validation AUC')
    plt.ylabel('No. of Epochs', fontsize=16)
    plt.xlabel('AUC Score', fontsize=16)
    plt.tick_params(labelsize=16)
    title = 'AUC Score by No. of Epochs'
    plt.title(title, loc = 'center', y=1.1, fontsize = 20)
    plt.tight_layout()
    plt.legend()
    saved_path = os.path.join(RESULTS_IMAGE_DIRECTORY, convert_filename(title))
    fig.savefig(saved_path, dpi=200, bbox_inches="tight")
    print('Saved to {}'.format(saved_path))

    fig = plt.figure(facecolor='w', figsize=(PLOT_WIDTH, PLOT_HEIGHT))
    plt.plot(epochs, loss,'r',label='Training Loss')
    plt.plot(epochs, val_loss,'b',label='Validation Loss')
    plt.ylabel('No. of Epochs', fontsize=16)
    plt.xlabel('Binary Cross Entropy', fontsize=16)
    plt.tick_params(labelsize=16)
    title = 'Binary Cross Entropy by No. of Epochs'
    plt.title(title, loc = 'center', y=1.1, fontsize = 20)
    plt.tight_layout()
    plt.legend()
    saved_path = os.path.join(RESULTS_IMAGE_DIRECTORY, convert_filename(title))
    fig.savefig(saved_path, dpi=200, bbox_inches="tight")
    print('Saved to {}'.format(saved_path))

    plt.show()

# model = build_nn(train_x)
def train_nn(model, train_x, train_y):
    checkpoint_path = os.path.join(RESULTS_DIRECTORY, "nn/weights.ckpt")
    checkpoint = ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=0, save_best_only = True)
    earlystopping = EarlyStopping(patience = 10, verbose=2, monitor='val_auroc', mode='max')
    tensorboard = TensorBoard(log_dir=os.path.join(RESULTS_DIRECTORY, 'nn/logs'))

    history = model.fit(train_x, train_y, epochs = 50, batch_size=32, validation_split = 0.3,
                        callbacks = [checkpoint, earlystopping, tensorboard])
    plot_nn_history(history)

    model.load_weights(checkpoint_path)
    return model

# Inspiration: https://www.kaggle.com/garethjns/microsoft-lightgbm-with-parameter-tuning-0-823
# For each fold of the train:
#   Train on other folds, validate with current fold to find best iteration
#   Predict for train and test with the best iteration
# Calcualte the average of all folds as the final prediction
def train_predict_lgb(estimator, train_x, train_y, test_x):
    train_predict= np.zeros(len(train_x))
    test_predict = np.zeros(len(test_x))
    importances = np.zeros(train_x.shape[1])
    FOLDS = 5
    folds = StratifiedKFold(n_splits=FOLDS, shuffle=True)

    count = 0
    for train_index, val_index in folds.split(train_x, train_y):
        # TRAIN LGBM
        count += 1
        print_info('LightGBM FOLD {}'.format(count))
        train_x_A, train_x_B = train_x.iloc[train_index], train_x.iloc[val_index]
        train_y_A, train_y_B = train_y.iloc[train_index], train_y.iloc[val_index]

        # estimator.fit(train_x_A, train_y_A, eval_metric='auc', eval_set=[(train_x_B, train_y_B)], verbose=200, early_stopping_rounds=100)
        estimator.fit(train_x_A, train_y_A, eval_metric='auc', eval_set=[(train_x_B, train_y_B)], verbose=200, early_stopping_rounds=10)

        # PREDICT TEST
        del train_x_A, train_x_B, train_y_A, train_y_B
        gc.collect()

        print_info('Making Prediction')
        train_predict += estimator.predict_proba(train_x,num_iteration=estimator.best_iteration_)[:, -1]/FOLDS
        test_predict += estimator.predict_proba(test_x,num_iteration=estimator.best_iteration_)[:, -1]/FOLDS
        importances += estimator.feature_importances_/FOLDS
    return estimator, importances, train_predict, test_predict

estimator = LogisticRegression(random_state=SEED)
def experiment(estimator, train_x, train_y, test_x, test_y, pca = False, fine_tune = False):
    if estimator == 'NeuralNetwork':
        estimator_name = 'NeuralNetwork'
    else:
        estimator_name = estimator.__class__.__name__
    importances = None

    print_sub_title('Experimenting {}; PCA Mode: {}; Fine Tune Mode: {}'.format(estimator_name, pca, fine_tune))

    # Transform if PCA
    if pca:
        train_x, test_x = pca_transform(train_x, test_x)

    if estimator_name == 'NeuralNetwork':
        """@TODO: Tuning"""
        # https://www.kaggle.com/cdeotte/neural-network-malware-0-67
        model = train_nn(build_nn(train_x), train_x, train_y)

    elif estimator_name == 'LGBMClassifier':
        if fine_tune:
            model, best_params = grid_search(estimator_name, estimator, train_x, train_y, pca)
            estimator = estimator.__class__(**best_params)
        model, importances, train_prob, test_prob = train_predict_lgb(estimator, train_x, train_y, test_x)

    # Train directly not fine tune
    elif not fine_tune:
        print_info('Start Fitting {}'.format(estimator_name))
        model = estimator.fit(train_x, train_y)
    else:
        print_info('Start Grid Searching {}'.format(estimator_name))
        model, best_params = grid_search(estimator_name, estimator, train_x, train_y, pca)

    if estimator_name != 'LGBMClassifier':
        train_prob, test_prob = make_prediction(model, train_x, test_x, estimator_name, pca, fine_tune)

    process_prediction(model, train_prob, train_y, test_prob, test_y,  estimator_name, pca, fine_tune)

    if not pca and estimator_name not in ['GaussianNB', 'NeuralNetwork']:
        process_feature_importances(model, importances, estimator_name, pca, fine_tune)

gridsearch_param = {'scoring': 'roc_auc', 'verbose': 2 , 'n_jobs': -1, 'cv': 3}
estimators_params_grid = {
    'LogisticRegression': {'C' : [10**i for i in range(-3, 4)], 'solver': ['saga']},
    'DecisionTreeClassifier': {'min_samples_split': [2000, 3000, 4000]},
    # 'RandomForestClassifier': {'n_estimators' : [10, 50, 100, 200], 'min_samples_split': [2000, 3000, 4000], 'random_state': [SEED]},
    'RandomForestClassifier': {'n_estimators' : [2], 'min_samples_split': [2000, 3000, 4000]},
    # 'lightgbm': {'num_leaves': [500, 1000, 1500, 2000, 2500]},
    'LGBMClassifier': {'num_leaves': [2500]},
    }


experiment(LogisticRegression(random_state=SEED), train_x, train_y, test_x, test_y, pca = False, fine_tune = False)
experiment(LogisticRegression(random_state=SEED), train_x, train_y, test_x, test_y, pca = True, fine_tune = False)
experiment(LogisticRegression(random_state=SEED), train_x, train_y, test_x, test_y, pca = False, fine_tune = True)
experiment(LogisticRegression(random_state=SEED), train_x, train_y, test_x, test_y, pca = True, fine_tune = True)

experiment(DecisionTreeClassifier(random_state=SEED), train_x, train_y, test_x, test_y, pca = False, fine_tune = False)
experiment(DecisionTreeClassifier(random_state=SEED), train_x, train_y, test_x, test_y, pca = True, fine_tune = False)
experiment(DecisionTreeClassifier(random_state=SEED), train_x, train_y, test_x, test_y, pca = False, fine_tune = True)
experiment(DecisionTreeClassifier(random_state=SEED), train_x, train_y, test_x, test_y, pca = True, fine_tune = True)


experiment(GaussianNB(), train_x, train_y, test_x, test_y, pca = False, fine_tune = False)
experiment(GaussianNB(), train_x, train_y, test_x, test_y, pca = True, fine_tune = False)

experiment(RandomForestClassifier(random_state=SEED), train_x, train_y, test_x, test_y, pca = False, fine_tune = False)
experiment(RandomForestClassifier(random_state=SEED), train_x, train_y, test_x, test_y, pca = True, fine_tune = False)
experiment(RandomForestClassifier(random_state=SEED), train_x, train_y, test_x, test_y, pca = False, fine_tune = True)
experiment(RandomForestClassifier(random_state=SEED), train_x, train_y, test_x, test_y, pca = True, fine_tune = True)

# lgbm = lgb.LGBMClassifier(n_estimators=10000, objective='binary', random_state = SEED, feature_fraction=0.7, learning_rate=0.05)
lgbm = lgb.LGBMClassifier(n_estimators=100, objective='binary', random_state = SEED, feature_fraction=0.7, learning_rate=0.05)
experiment(lgbm, train_x, train_y, test_x, test_y, pca = False, fine_tune = False)
experiment(lgbm, train_x, train_y, test_x, test_y, pca = True, fine_tune = False)
experiment(lgbm, train_x, train_y, test_x, test_y, pca = False, fine_tune = True)
experiment(lgbm, train_x, train_y, test_x, test_y, pca = True, fine_tune = True)

experiment('NeuralNetwork', train_x, train_y, test_x, test_y, pca = False, fine_tune = False)

""" Meta Model (Second Level Model)"""
"""@TODO"""
# Find best mode for each model and the finetune params if any
# Split train into trainA, trainB
# fit on trainA,
# Predict for metaB and metaT
# Train meta model on metaB
# Predict for test using meta model
# LogisticRegression(**load_obj(os.path.join(RESULTS_FT_DIRECTORY, 'Params-{}{}.pkl'.format(estimator_name, '+PCA' if pca else ''))))
# np.load(os.path.join(RESULTS_META_DIRECTORY, 'train-{}{}{}.npy'.format(estimator_name, 'test-{}{}{}'.format(estimator_name, '+PCA' if pca else '', '+FT' if fine_tune else ''))))
