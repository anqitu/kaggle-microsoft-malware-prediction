# Setting
SAMPLE = True

# Import libraries
from setting import *
from util import *

import os
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import roc_curve, auc, roc_auc_score
from sklearn.decomposition import PCA
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
import lightgbm as lgb

# Ignore warnings
import warnings
warnings.filterwarnings('ignore')

# Set display options
pd.options.display.max_rows = 100
pd.options.display.max_columns = 100
pd.options.display.width = 1000

# Set Global Random Seed -------------------------------------------------------
print_title('Set Global Random Seed')
np.random.seed(SEED)
print_info('Set global random seed to {}'.format(SEED))

# Load data --------------------------------------------------------------------
print_title('Load Data')
print_info('Start loading data')

if not os.path.isfile(ORIGIN_DATA_PATH):
    print_info("File '{}' does not exist.".format(ORIGIN_DATA_PATH))
    print_info("Please download it according to the instructions in README.md")
    quit()

if SAMPLE:
    origin_data = pd.read_csv(ORIGIN_DATA_PATH, nrows = 10000, dtype=ORIGIN_LOAD_TYPES, na_values=['UNKNOWN', 'Unknown'])
    # origin_data['MachineIdentifier'] = origin_data.index.astype('uint32')
else:
    origin_data = pd.read_csv(ORIGIN_DATA_PATH, dtype=ORIGIN_LOAD_TYPES, na_values=['UNKNOWN', 'Unknown'])
    # origin_data['MachineIdentifier'] = origin_data.index.astype('uint32')

print_info('Finish loading data')

# Get data summary of missing frequency and unique levels ----------------------
print_title('Get Data Summary')
if SAMPLE and os.path.isfile(os.path.join(CHECK_DATA_DIRECTORY, 'data_summary.csv')):
    print_info('Read from existing data_summary.csv')
    summary_df = pd.read_csv(os.path.join(CHECK_DATA_DIRECTORY, 'data_summary.csv'))
else:
    print_info('Creating data summary')
    summary_df = origin_data.describe(include = 'all')
    summary_df = summary_df.transpose()
    summary_df.index.name = 'Column'
    summary_df['count'] = summary_df['count'].astype(int)
    missing_percentage_df = get_null_percentage(origin_data)
    missing_percentage_df = missing_percentage_df.set_index('Column')
    summary_df = pd.concat([summary_df, missing_percentage_df], axis = 1).reset_index()
summary_df = summary_df[summary_df['Column'] != TARGET]

# Drop Features ----------------------------------------------------------------
print_title('Drop Features')

print_info("Features with no relevance -> To be dropped:")
features_irrelevant= ['MachineIdentifier']
for col in features_irrelevant:
    print(col)

print_info("Features with more than half missing -> To be dropped:")
features_more_than_half_missing = list(summary_df[summary_df['Missing Frequency'] >= 0.5 ]['Column'])
for col in features_more_than_half_missing:
    print(col)

print_info("Features with 98% or more of the data contained in one category value -> To be dropped:")
summary_df['top_level_percentage'] = summary_df['freq'] / summary_df['count']
features_98_perc_in_one_category_value = list(summary_df[summary_df['top_level_percentage'] > 0.98]['Column'])
for col in features_98_perc_in_one_category_value:
    print(col)

features_to_be_dropped = list(set(features_irrelevant + features_more_than_half_missing + features_98_perc_in_one_category_value))
features_to_be_kept = [col for col in summary_df['Column'] if col not in features_to_be_dropped]
print_info("Leng of features with to be dropped: {}".format(len(features_to_be_dropped)))
for col in features_to_be_dropped:
    print(col)
print_info("Leng of features with to be kept: {}".format(len(features_to_be_kept)))
for col in features_to_be_kept:
    print(col)

def select_features(df, features_to_be_dropped):
    print_info('Selecting features')
    df.drop(columns = features_to_be_dropped, inplace=True)
    print_info('No. of features dropped: {}'.format(len(features_to_be_dropped)))
    print_info("No. of features kept: {}".format(len(df.columns)))
select_features(origin_data, features_to_be_dropped)
summary_df = summary_df[summary_df['Column'].isin(features_to_be_kept)]

# Fill missing values ----------------------------------------------------------
print_title('Identfy and Fill Missing Values')

features_missing_lt_1_perc = list(summary_df[(summary_df['Missing Frequency'].round(2) <= 0.01) & (summary_df['Missing Frequency'] != 0)]['Column'])
features_to_be_filled_by_mode = [col for col in features_missing_lt_1_perc if col in CATEGORICAL_FEATURES]
features_to_be_filled_by_median = [col for col in features_missing_lt_1_perc if col in NUMERICAL_FEATURES]
print_info("Features (categorical) with missing frequency <= 0.01 -> To be filled by mode:")
for col in features_to_be_filled_by_mode:
    print(col)
print_info("Features (numeric) with missing frequency <= 0.01 -> To be filled by median:")
for col in features_to_be_filled_by_median:
    print(col)

features_missing_mt_1_perc = list(summary_df[(summary_df['Missing Frequency'].round(2) > 0.01)]['Column'])
features_to_be_filled_by_unknown = [col for col in features_missing_mt_1_perc if col in CATEGORICAL_FEATURES]
print_info("Features (categorical) with missing frequency > 0.01 -> To be filled by unknown:")
for col in features_to_be_filled_by_unknown:
    print(col)
print_info("Features (numeric) with missing frequency > 0.01 -> To be ?:")
for col in [col for col in features_missing_mt_1_perc if col not in features_to_be_filled_by_unknown]:
    print(col)

def fill_missing_values(df, features_to_be_filled_by_mode = [], features_to_be_filled_by_median = [], features_to_be_filled_by_unknown = []):
    print_info('Filling missing values')
    for col in features_to_be_filled_by_mode:
        df[col] = df[col].fillna(df[col].mode()[0])
    for col in features_to_be_filled_by_median:
        df[col] = df[col].fillna(df[col].median())
    for col in features_to_be_filled_by_unknown:
        df[col] = df[col].cat.add_categories('unknown').fillna('unknown')
    df['Census_InternalBatteryNumberOfCharges'] = df['Census_InternalBatteryNumberOfCharges'].fillna('unknown').astype('str')
    print_info('Count of missing values: {}'.format(df.isnull().sum().sum()))

fill_missing_values(origin_data, features_to_be_filled_by_mode, features_to_be_filled_by_median, features_to_be_filled_by_unknown)

# Handle Invalid Values --------------------------------------------------------
print_title('Identify and Handle Invalid Values')
def handle_invalid_values(df):
    print_info('Handling invalid values')
    df['SmartScreen']=df['SmartScreen'].str.lower()
    df['SmartScreen'].replace({"promt":"prompt",
                               "00000000":"0",
                               "enabled":"on"},inplace=True)
    df['Census_InternalPrimaryDisplayResolutionHorizontal'] = df['Census_InternalPrimaryDisplayResolutionHorizontal'].replace(-1, df['Census_InternalPrimaryDisplayResolutionHorizontal'].median())
    df['Census_InternalPrimaryDisplayResolutionVertical'] = df['Census_InternalPrimaryDisplayResolutionVertical'].replace(-1, df['Census_InternalPrimaryDisplayResolutionVertical'].median())

handle_invalid_values(origin_data)

# Identify and Handle Outliers For Numeric Attributes --------------------------
print_title('Identify and Handle Outliers')
def remove_outliers(df):
    outliers_df = df[df['Census_PrimaryDiskTotalCapacity'] > (10**12)]
    print("The two extremely large outliers: {}".format(list(outliers_df['Census_PrimaryDiskTotalCapacity'].unique())))
    print("Number of outliers removed: {}".format(outliers_df.shape[0]))
    df = df[df['Census_PrimaryDiskTotalCapacity'] < (10**12)]

remove_outliers(origin_data)

"""@TODO"""
# https://www.kaggle.com/cdeotte/time-series-eda-malware-0-64/notebook
# Encode ---------------------------------------------------------------------
print_title('Encode Categorical Features')
features_binary = [col for col in list(summary_df[summary_df['unique'] == 2]['Column']) if col not in features_missing_mt_1_perc]
features_need_EN = list(set([col for col in list(summary_df[summary_df['unique'] > 2]['Column'])] + features_to_be_filled_by_unknown))
features_need_EN.append('Census_InternalBatteryNumberOfCharges')
# features_need_BE = {}
# features_need_TE = {}
# features_need_FE = []

print_info("No. of categorical features with binary levels (0/1 by default) -> Do Nothing: {}".format(len(features_binary)))
for col in features_binary:
    print(col)
    origin_data[col] = origin_data[col].astype('int8')

print_info("No. of categorical features with more than 2 levels -> To be encoded: {}".format(len(features_need_EN)))
for col in features_need_EN:
    print(col)

le = LabelEncoder()
for col in features_need_EN:
    origin_data[col] = le.fit_transform(origin_data[col])

"""@TODO Split by Time"""
# Split Train and Test ---------------------------------------------------------
print_title('Split Train and Test')
print_info('Start splitting data')
origin_y = origin_data[TARGET]
origin_x = origin_data.drop(columns = TARGET)
train_x, test_x, train_y, test_y = train_test_split(origin_x, origin_y, test_size=0.3, stratify = origin_y, random_state = SEED)
print_info('Trainser shape: {} | Testset shape: {}'.format(train_x.shape, test_x.shape))
print_info('Trainset Distribution: ')
print(train_y.value_counts() / train_y.shape[0])
print_info('Testset Distribution: ')
print(test_y.value_counts() / test_y.shape[0])

# Normalizing ------------------------------------------------------------------
print_title('Normalize Numeric Features')
# features_need_NM = [col for col in NUMERICAL_FEATURES if col in features_to_be_kept]
# features_need_NM.remove('Census_InternalBatteryNumberOfCharges')
# print_info("No. of numeric features to be normalized: {}".format(len(features_need_NM)))
# for col in features_need_NM:
#     # train_x[col] = scaler.fit_transform(train_x[[col]])
#     print(col)
scaler = MinMaxScaler()
train_x[train_x.columns] = scaler.fit_transform(train_x)
test_x[train_x.columns] = scaler.transform(test_x)
test_x.describe()

# PCA --------------------------------------------------------------------------
print_info('Finding n_components that could explain at least 90% variances')
pca = PCA(n_components=train_x.shape[-1])
pca.fit(train_x)
ratio_cumsum = pca.explained_variance_ratio_.cumsum()
ratio_df = pd.DataFrame(data = { 'No. of Components': range(1, len(pca.explained_variance_ratio_)+1),'Explained Variance Ratio': pca.explained_variance_ratio_, 'Cum Explained Variance Ratio': ratio_cumsum})
ratio_df.to_csv(os.path.join(RESULTS_DIRECTORY, 'PCA_Explained_Variance_Ratio.csv'), index = False)
plot_pca_ratio_cumsum(ratio_cumsum, save_directory=RESULTS_IMAGE_DIRECTORY, show = False)

N_COMPONENTS = sum(ratio_cumsum<0.95)+1
pca = PCA(n_components=N_COMPONENTS)
pca.fit(train_x)
ratio_cumsum = pca.explained_variance_ratio_.cumsum()
print_info('Explained variance by {} n_components: {:.3f}'.format(N_COMPONENTS, ratio_cumsum[-1]))

# Build Model ------------------------------------------------------------------
def pca_transform(train_x, test_x):
    pca = PCA(n_components=N_COMPONENTS)
    train_x = pca.fit_transform(train_x)
    test_x = pca.transform(test_x)
    print_info('PCA transformed train_x shape: {}'.format(train_x.shape))
    return train_x, test_x

def grid_search(estimator_name, estimator, train_x, train_y, pca):
    print_info('Start Grid Searching {}'.format(estimator_name))
    gridsearcher = GridSearchCV(estimator = estimator(), param_grid = estimators_params_grid[estimator_name], **gridsearch_param)
    model = gridsearcher.fit(train_x, train_y)
    cv_results_df = pd.DataFrame(gridsearcher.cv_results_)
    cv_results_df.to_csv(os.path.join(RESULTS_FT_DIRECTORY, 'cv_results-{}{}.csv'.format(estimator_name, '+PCA' if pca else '')), index = False)
    print_info('Grid Search best ROC Score: {}'.format(gridsearcher.best_score_))
    print('Best Params: \n{}'.format(gridsearcher.best_params_))
    return model

def make_prediction(model, train_x, test_x, estimator_name, pca, fine_tune):
    print_info('Start Making Prediction with Best Estimator {}'.format(estimator_name))
    # train_predict = model.predict(train_x)
    # test_predict = model.predict(test_x)
    train_prob = model.predict_proba(train_x)[:, -1]
    test_prob = model.predict_proba(test_x)[:, -1]

    """@TODO: Save prediction results"""

    return train_prob, test_prob

def save_score(estimator_name, pca, fine_tune, train_roc_score, test_roc_score):
    scores_fpath = os.path.join(RESULTS_DIRECTORY, 'scores.csv')
    try:
        scores_df = pd.read_csv(scores_fpath)
    except:
        scores_df = pd.DataFrame(columns = ['Model', 'PCA', 'Fine Tune', 'Train ROC Score', 'Test ROC Score'])

    scores_df.loc[scores_df.shape[0]] = [estimator_name, pca, fine_tune, train_roc_score, test_roc_score]
    scores_df.to_csv(scores_fpath, index = False)

def process_prediction(model, train_prob, train_y, test_prob, test_y,  estimator_name, pca, fine_tune):

    plot_roc_curve(train_y, train_prob, save_directory = RESULTS_IMAGE_DIRECTORY, show = False, title = '{} ROC Curve - {}{}{}'.format('Train', estimator_name, '+PCA' if pca else '', '+FT' if fine_tune else ''))
    plot_roc_curve(test_y, test_prob, save_directory = RESULTS_IMAGE_DIRECTORY, show = False, title = '{} ROC Curve - {}{}{}'.format('Test', estimator_name, '+PCA' if pca else '', '+FT' if fine_tune else ''))

    train_roc_score = roc_auc_score(train_y, train_prob)
    test_roc_score = roc_auc_score(test_y, test_prob)

    save_score(estimator_name, pca, fine_tune, train_roc_score, test_roc_score)

    print_info('ROC Score for {}: {:.3f} (Train)'.format(estimator_name, train_roc_score))
    print_info('ROC Score for {}: {:.3f} (Test)'.format(estimator_name, test_roc_score))

def process_feature_importances(model):
    """@TODO"""

def build_nn(x_train):
    model = Sequential()
    model.add(Dense(512, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.2))

    model.add(Dense(256, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.2))

    model.add(Dense(128, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.2))

    model.add(Dense(64, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.2))

    model.add(Dense(32, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.2))

    model.add(Dense(16, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.2))

    model.add(Dense(8, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.2))

    model.add(Dense(1, activation='sigmoid'))

    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

    return model


def experiment(estimator, train_x, train_y, test_x, test_y, pca = False, fine_tune = False):
    if estimator == 'NeuralNetwork':
        estimator_name = 'NeuralNetwork'
    else:
        try:
            estimator_name = estimator().__class__.__name__
        except:
            estimator_name = estimator.__name__

    print_sub_title('Experimenting {}; PCA Mode: {}; Fine Tune Mode: {}'.format(estimator_name, pca, fine_tune))

    # Transform if PCA
    if pca:
        train_x, test_x = pca_transform(train_x, test_x)

    # Train directly if no parameters available for tuning or not fine tune
    if not estimators_params_grid[estimator_name] or not fine_tune:
        print_info('Start Fitting {}'.format(estimator_name))
        model = estimator().fit(train_x, train_y)
    elif estimator_name == 'lightgbm':
        pass
        """@TODO"""
        # MAX_ROUNDS = 500
        # dtrain = lgb.Dataset(x_train_selected, label=y_train[:, i],
        #     weight=pd.concat([items["perishable"]] * NUM_WEEK_CONCATS) * 0.25 + 1)
        # dval = lgb.Dataset(x_val_selected, label=y_val[:, i], reference=dtrain,
        #     weight=items["perishable"] * 0.25 + 1)
        # start = time.perf_counter()
        # if lgb_cat:
        #     model = lgb.train(estimatos_params_grid[estimator_name], dtrain, num_boost_round=MAX_ROUNDS,
        #         valid_sets=[dtrain, dval], early_stopping_rounds=50, verbose_eval=50,
        #         categorical_feature = categorical_features)
        # else:
        #     model = lgb.train(estimatos_params_grid[estimator_name], dtrain, num_boost_round=MAX_ROUNDS,
        #         valid_sets=[dtrain, dval], early_stopping_rounds=50, verbose_eval=50,
        #         categorical_feature = [])
        # runtime_df['Run Time Day{}'.format(i)] = time.perf_counter() - start
        #
        # y_pred_train = model.predict(x_train_selected, num_iteration=model.best_iteration or MAX_ROUNDS)
        # y_pred_val = model.predict(x_val_selected, num_iteration=model.best_iteration or MAX_ROUNDS)
        # y_pred_test = model.predict(x_test_selected, num_iteration=model.best_iteration or MAX_ROUNDS)
        #
        # importances['Day{}'.format(i)] = model.feature_importance("gain")
    elif estimator_name is 'NeuralNetwork':
        pass
        """@TODO"""

    else:
        model = grid_search(estimator_name, estimator, train_x, train_y, pca)

    train_prob, test_prob = make_prediction(model, train_x, test_x, estimator_name, pca, fine_tune)
    process_prediction(model, train_prob, train_y, test_prob, test_y,  estimator_name, pca, fine_tune)

gridsearch_param = {'scoring': 'roc_auc', 'verbose': 2 , 'n_jobs': -1, 'cv': 3}
estimators_params_grid = {
    'LogisticRegression': {'C' : [10**i for i in range(-3, 4)], 'solver': ['saga']},
    'DecisionTreeClassifier': {'min_samples_split': [2000, 3000, 4000], 'random_state': [SEED]},
    'GaussianNB':{},
    'RandomForestClassifier': {'n_estimators' : [10, 50, 100, 200], 'min_samples_split': [2000, 3000, 4000], 'random_state': [SEED]},
    'lightgbm': {
        'objective': 'binary',
        'n_estimators': 10000,
        'num_leaves': 2048,
        'min_child_samples': 200,
        'learning_rate': 0.04,
        'feature_fraction': 0.8,
        'bagging_fraction': 0.8,
        'bagging_freq': 3,
        'metric': 'l2_root',
        'num_threads': 4,
        'random_state': SEED
        }}
experiment(LogisticRegression, train_x, train_y, test_x, test_y, pca = False, fine_tune = False)
experiment(LogisticRegression, train_x, train_y, test_x, test_y, pca = True, fine_tune = False)
experiment(LogisticRegression, train_x, train_y, test_x, test_y, pca = False, fine_tune = True)
experiment(LogisticRegression, train_x, train_y, test_x, test_y, pca = True, fine_tune = True)

experiment(DecisionTreeClassifier, train_x, train_y, test_x, test_y, pca = False, fine_tune = False)
experiment(DecisionTreeClassifier, train_x, train_y, test_x, test_y, pca = True, fine_tune = False)
experiment(DecisionTreeClassifier, train_x, train_y, test_x, test_y, pca = False, fine_tune = True)
experiment(DecisionTreeClassifier, train_x, train_y, test_x, test_y, pca = True, fine_tune = True)

experiment(GaussianNB, train_x, train_y, test_x, test_y, pca = False, fine_tune = False)
experiment(GaussianNB, train_x, train_y, test_x, test_y, pca = True, fine_tune = False)

# experiment(RandomForestClassifier, train_x, train_y, test_x, test_y, pca = False, fine_tune = False)
# experiment(RandomForestClassifier, train_x, train_y, test_x, test_y, pca = True, fine_tune = False)
# experiment(RandomForestClassifier, train_x, train_y, test_x, test_y, pca = False, fine_tune = True)
# experiment(RandomForestClassifier, train_x, train_y, test_x, test_y, pca = True, fine_tune = True)

""" Meta Model (Second Level Model)"""
"""@TODO"""
