# Setting
SAMPLE = True

# Import libraries
from setting import *
from util import *

import time
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder

summary_df = pd.read_csv(os.path.join(CHECK_DATA_DIRECTORY, 'data_summary.csv'))

# Drop Features ----------------------------------------------------------------
print()
print_info("Features with no relevance -> To be dropped:")
features_irrelevant= ['MachineIdentifier']
for col in features_irrelevant:
    print(col)

print()
print_info("Features with more than half missing -> To be dropped:")
features_more_than_half_missing = list(summary_df[summary_df['Missing Frequency'] >= 0.5 ]['Column'])
for col in features_more_than_half_missing:
    print(col)

print()
print_info("Features with 98% or more of the data contained in one category value -> To be dropped:")
summary_df['top_level_percentage'] = summary_df['freq'] / summary_df['count']
features_98_perc_in_one_category_value = list(summary_df[summary_df['top_level_percentage'] > 0.98]['Column'])
for col in features_98_perc_in_one_category_value:
    print(col)

features_to_be_dropped = list(set(features_irrelevant + features_more_than_half_missing + features_98_perc_in_one_category_value))
print()
print_info("Leng of features with to be dropped: {}".format(len(features_to_be_dropped)))
for col in features_to_be_dropped:
    print(col)

features_to_be_kept = [col for col in summary_df['Column'] if col not in features_to_be_dropped]
print()
print_info("Leng of features with to be kept: {}".format(len(features_to_be_kept)))
for col in features_to_be_kept:
    print(col)

summary_df = summary_df[summary_df['Column'].isin(features_to_be_kept)]

def select_features(df):
    print_info('Selecting features')
    df.drop(columns = features_to_be_dropped, inplace=True)
    print_info('No. of features dropped: {}'.format(len(features_to_be_dropped)))
    print_info("No. of features kept: {}".format(len(df.columns)))

# Fill missing values ----------------------------------------------------------
print_title('Identify and Fill Missing Values')

features_missing_lt_1_perc = list(summary_df[(summary_df['Missing Frequency'].round(2) <= 0.01) & (summary_df['Missing Frequency'] != 0)]['Column'])
features_to_be_filled_by_mode = [col for col in features_missing_lt_1_perc if col in CATEGORICAL_FEATURES]
features_to_be_filled_by_median = [col for col in features_missing_lt_1_perc if col in NUMERICAL_FEATURES]
print_info("Features (categorical) with missing frequency <= 0.01 -> To be filled by mode:")
for col in features_to_be_filled_by_mode:
    print(col)
print_info("Features (numeric) with missing frequency <= 0.01 -> To be filled by median:")
for col in features_to_be_filled_by_median:
    print(col)

features_missing_mt_1_perc = list(summary_df[(summary_df['Missing Frequency'].round(2) > 0.01)]['Column'])
features_to_be_filled_by_unknown = [col for col in features_missing_mt_1_perc if col in CATEGORICAL_FEATURES]
print_info("Features (categorical) with missing frequency > 0.01 -> To be filled by unknown:")
for col in features_to_be_filled_by_unknown:
    print(col)
print_info("Features (numeric) with missing frequency > 0.01 -> To be ?:")
for col in [col for col in features_missing_mt_1_perc if col not in features_to_be_filled_by_unknown]:
    print(col)

def fill_missing_values(df):
    print_info('Filling missing values')
    for col in features_to_be_filled_by_mode:
        df[col] = df[col].fillna(df[col].mode()[0])
    for col in features_to_be_filled_by_median:
        df[col] = df[col].fillna(df[col].median())
    for col in features_to_be_filled_by_unknown:
        print(col)
        df[col] = df[col].cat.add_categories('unknown').fillna('unknown')
    df['Census_InternalBatteryNumberOfCharges'] = df['Census_InternalBatteryNumberOfCharges'].fillna('unknown').astype('str')
    print_info('Count of missing values: {}'.format(df.isnull().sum().sum()))

# Handle Invalid Values --------------------------------------------------------
print_title('Identify and Handle Invalid Values')
def handle_invalid_values(df):
    print_info('Handling invalid values')

    print_info("SmartScreen (Different labels of same word with different case) - Lowercase values")
    df['SmartScreen']=df['SmartScreen'].str.lower()
    df['SmartScreen'].replace({"promt":"prompt",
                                "promprt":"prompt",
                                "00000000":"0",
                                "enabled":"on",
                                "of":"off" ,
                                "deny":"0" , # just one
                                "requiredadmin":"requireadmin"},inplace=True)
    print_info("Census_InternalPrimaryDisplayResolutionHorizontal (invalid values as -1) - Convert invalid values -1 to median/mode")
    df['Census_InternalPrimaryDisplayResolutionHorizontal'] = df['Census_InternalPrimaryDisplayResolutionHorizontal'].replace(-1, df['Census_InternalPrimaryDisplayResolutionHorizontal'].median())

    print_info("Census_InternalPrimaryDisplayResolutionVertical (invalid values as -1) - Convert invalid values -1 to median/mode")
    df['Census_InternalPrimaryDisplayResolutionVertical'] = df['Census_InternalPrimaryDisplayResolutionVertical'].replace(-1, df['Census_InternalPrimaryDisplayResolutionVertical'].median())

# Identify and Handle Outliers For Numeric Attributes --------------------------
print_title('Identify and Handle Outliers')
def remove_outliers(df):
    outliers_df = df[df['Census_PrimaryDiskTotalCapacity'] > (10**12)]
    print("The two extremely large outliers: {}".format(list(outliers_df['Census_PrimaryDiskTotalCapacity'].unique())))
    print("Number of outliers removed: {}".format(outliers_df.shape[0]))
    df = df[df['Census_PrimaryDiskTotalCapacity'] < (10**12)]

"""@TODO"""
# https://www.kaggle.com/cdeotte/time-series-eda-malware-0-64/notebook
# Encode ---------------------------------------------------------------------

# Map features to datetime
time_series_features = ['AvSigVersion', 'Census_OSVersion']
def map_feature_to_time_series(df, column):
    map_dict = np.load(os.path.join(DATA_PATH, column + 'Timestamps.npy'), allow_pickle=True)[()]
    df['{}_time_series'.format(column)] = df[column].map(map_dict)
    df['{}_time_series'.format(column)] = df['{}_time_series'.format(column)].apply(lambda date_time: date_time.timestamp())
    print(df['{}_time_series'.format(column)])

def map_values(df):
    print_info('Mapping values')

    # Map time series features
    for column in time_series_features:
        map_feature_to_time_series(df, column)
    

print_title('Encode Categorical Features')
features_binary = [col for col in list(summary_df[summary_df['unique'] == 2]['Column']) if col not in features_missing_mt_1_perc]
features_need_EN = list(set([col for col in list(summary_df[summary_df['unique'] > 2]['Column']) if col not in time_series_features] + features_to_be_filled_by_unknown))

print_info("Census_InternalBatteryNumberOfCharges (3.01% Missing & 25.38% are 4294967296 which represents inf in Python) - (filled with unknown & To be encoded)")
features_need_EN.append('Census_InternalBatteryNumberOfCharges')

print_info("No. of categorical features with binary levels (0/1 by default) -> Do Nothing: {}".format(len(features_binary)))
for col in features_binary:
    print(col)

print_info("No. of categorical features with more than 2 levels -> To be encoded: {}".format(len(features_need_EN)))
for col in features_need_EN:
    print(col)

def encode_categorical_values(df):
    print_info('Encoding categorical values')
    for col in features_binary:
        df[col] = df[col].astype('int8')

    le = LabelEncoder()
    for col in features_need_EN:
        df[col] = le.fit_transform(df[col])

# Normalizing ------------------------------------------------------------------
def normalize_data(train_x, test_x):
    print_info('Normalizing data')
    # features_need_NM = [col for col in NUMERICAL_FEATURES if col in features_to_be_kept]
    # features_need_NM.remove('Census_InternalBatteryNumberOfCharges')
    # print_info("No. of numeric features to be normalized: {}".format(len(features_need_NM)))
    # for col in features_need_NM:
    #     # train_x[col] = scaler.fit_transform(train_x[[col]])
    #     print(col)
    scaler = MinMaxScaler()
    train_x[train_x.columns] = scaler.fit_transform(train_x)
    test_x[train_x.columns] = scaler.transform(test_x)
